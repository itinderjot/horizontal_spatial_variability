{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: panels a and b\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import moment\n",
    "import variogram_helper_functions\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.rcParams[\"font.family\"] = \"Roboto\"\n",
    "matplotlib.rcParams[\"font.sans-serif\"] = [\"Roboto\"]  # For non-unicode text\n",
    "matplotlib.rcParams['axes.labelsize'] = 18\n",
    "matplotlib.rcParams['axes.titlesize'] = 18\n",
    "matplotlib.rcParams['xtick.labelsize'] = 18\n",
    "matplotlib.rcParams['ytick.labelsize'] = 18\n",
    "matplotlib.rcParams['legend.fontsize'] = 18\n",
    "matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "\n",
    "\n",
    "def generate_rough_and_smooth_surfaces(size):\n",
    "     # Generate a rough field using random noise\n",
    "    random_field = np.random.randn(size,size)#*100\n",
    "\n",
    "    # Apply a Gaussian filter to create a smooth field\n",
    "    sigma = 10  # Standard deviation for the Gaussian kernel (controls smoothness)\n",
    "    rough_field = gaussian_filter(random_field, sigma=0.6)\n",
    "    #rough_field = random_field\n",
    "    smooth_field = gaussian_filter(random_field, sigma=sigma)\n",
    "    smooth_field = (smooth_field - np.mean(smooth_field)) / np.std(smooth_field) * np.std(rough_field) + np.mean(rough_field)\n",
    "    print('min max of rough surface = ',np.min(rough_field),np.max(rough_field))\n",
    "    print('min max of smooth surface = ',np.min(smooth_field),np.max(smooth_field))\n",
    "    return rough_field, smooth_field\n",
    "\n",
    "\n",
    "# Compute statistical moments\n",
    "def compute_moments(field, name):\n",
    "    mean = np.mean(field)\n",
    "    variance = np.var(field)\n",
    "    skewness = moment(field.flatten(), moment=3) / np.std(field)**3  # Third moment (skewness)\n",
    "    kurtosis = moment(field.flatten(), moment=4) / np.var(field)**2  # Fourth moment (kurtosis)\n",
    "    fifth_moment = moment(field.flatten(), moment=5) / np.std(field)**5  # Fifth moment\n",
    "\n",
    "    print(f\"{name} Field Moments:\")\n",
    "    print(f\"  Mean: {mean:.4f}\")\n",
    "    print(f\"  Variance: {variance:.4f}\")\n",
    "    print(f\"  Skewness: {skewness:.4f}\")\n",
    "    print(f\"  Kurtosis: {kurtosis:.4f}\")\n",
    "    print(f\"  Fifth Moment: {fifth_moment:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "######----------------------------------------------------------------------\n",
    "np.random.seed(25)\n",
    "# Set grid size\n",
    "size = 200\n",
    "rough_field, smooth_field = generate_rough_and_smooth_surfaces(size)\n",
    "\n",
    "compute_moments(rough_field, \"Rough\")\n",
    "compute_moments(smooth_field, \"Smooth\")\n",
    "\n",
    "\n",
    "# Plot the two fields\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "#Rough field plot\n",
    "im1 = axes[0].contourf(rough_field, cmap='viridis', origin='lower', levels=np.arange(-2., 2.05, 0.05), extend='both')\n",
    "axes[0].set_title(\"Field A (rough)\")\n",
    "axes[0].set_xlabel(\"distance (km)\")\n",
    "axes[0].set_ylabel(\"distance (km)\")\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Add colorbar for rough field\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0], orientation='horizontal', fraction=0.046, pad=0.2)\n",
    "#cbar1.set_label(label='',size=5)\n",
    "cbar1.ax.tick_params(labelsize=11)  \n",
    "\n",
    "# Smooth field plot\n",
    "im2 = axes[1].contourf(smooth_field, cmap='viridis', origin='lower', levels=np.arange(-2., 2.05, 0.05), extend='both')\n",
    "axes[1].set_title(\"Field B (smooth)\")\n",
    "axes[1].set_xlabel(\"distance (km)\")\n",
    "axes[1].set_ylabel(\"distance (km)\")\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Add colorbar for smooth field\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1], orientation='horizontal', fraction=0.046, pad=0.2)\n",
    "#cbar2.set_label(label='',size=5)\n",
    "cbar2.ax.tick_params(labelsize=11)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('paper_1_new_fig1_panels_a_b.png',dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: panels c and d\n",
    "\n",
    "import variogram_helper_functions\n",
    "\n",
    "\n",
    "def plot_variogram_toy(TEMP_DATA,SAMPLE_SIZE,BIN_FUNCTION,ESTIMATOR):\n",
    "    y_dim, x_dim     = np.shape(TEMP_DATA)\n",
    "    coords = variogram_helper_functions.produce_random_coords(x_dim,y_dim,SAMPLE_SIZE)                           \n",
    "    nonnan_coords, nonnan_values = variogram_helper_functions.get_values_at_random_coords(TEMP_DATA, coords)\n",
    "    max_lag = np.sqrt(x_dim**2 + y_dim**2)/2.0\n",
    "    V, x1, y1 = variogram_helper_functions.make_variogram(nonnan_coords, nonnan_values, 50, max_lag, DX = 1.0, BIN_FUNCTION=BIN_FUNCTION,ESTIMATOR=ESTIMATOR)\n",
    "    return V, x1, y1\n",
    "\n",
    "nsamples = 10000\n",
    "\n",
    "V1, bins1, vario1  = plot_variogram_toy(rough_field,nsamples,'even','matheron')\n",
    "print('----')\n",
    "V2, bins2, vario2  = plot_variogram_toy(smooth_field,nsamples,'even','matheron')\n",
    "print('------------\\n\\n')\n",
    "\n",
    "\n",
    "S1, bins_str_func1, str_func1  = plot_variogram_toy(rough_field,nsamples,'even','first_order_structure_function')\n",
    "print('----')\n",
    "S2, bins_str_func2, str_func2  = plot_variogram_toy(smooth_field,nsamples,'even','first_order_structure_function')\n",
    "print('------------\\n\\n')\n",
    "\n",
    "\n",
    "fig, axes    = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "axes[0].plot(bins_str_func1, str_func1, label='First-Order SF',color='g',linewidth=3)\n",
    "axes[0].plot(bins1, vario1, label='Variogram',color='#999999',linewidth=3)\n",
    "#axes[0].set_title('Variogram/Order 1 Structure Function')\n",
    "axes[0].set_xlabel('Spatial lag (km)')\n",
    "axes[0].set_ylabel('Variogram/First-Order Structure Function')# $(arbitrary-unit^{2})$')\n",
    "axes[0].set_ylim([0,1.3])\n",
    "\n",
    "axes[1].plot(bins_str_func2, str_func2, label='First-Order SF',color='g',linewidth=3)\n",
    "axes[1].plot(bins2, vario2, label='Variogram',color='#999999',linewidth=3)\n",
    "#axes[1].set_title('Variogram')\n",
    "axes[1].set_xlabel('Spatial lag (km)')\n",
    "axes[1].set_ylabel('Variogram/First-Order Structure Function')# $(arbitrary-unit^{2})$')\n",
    "axes[1].set_ylim([0,1.3])\n",
    "\n",
    "axes[0].legend(fontsize=15)\n",
    "axes[1].legend(fontsize=15)\n",
    "\n",
    "axes[0].grid(True, which=\"both\", ls=\"--\")  # Grid for both axes in log scale\n",
    "axes[1].grid(True, which=\"both\", ls=\"--\")  # Grid for both axes in log scale\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('paper_1_new_fig1_panels_c_d.png',dpi=150,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: panels e and f\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Define a linear model for curve fitting\n",
    "def linear_model(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "def fit_data(spatial_lags,structure_function_vals):\n",
    "\n",
    "    log_bins = np.log10(spatial_lags)\n",
    "    log_exp_variogram = np.log10(structure_function_vals)\n",
    "\n",
    "    # Fit the data\n",
    "    params, cov = curve_fit(linear_model, log_bins, log_exp_variogram)\n",
    "    slope, intercept = params\n",
    "\n",
    "    slope_var = cov[0, 0]  # Variance of the slope\n",
    "\n",
    "    # Calculate the fitted line\n",
    "    fitted_line = linear_model(log_bins, slope, intercept)\n",
    "\n",
    "    # calculate R^2 \n",
    "    residuals = log_exp_variogram - linear_model(log_bins,  slope, intercept)\n",
    "    ss_res    = np.sum(residuals**2)\n",
    "    #You can get the total sum of squares (ss_tot) with\n",
    "    ss_tot    = np.sum((log_exp_variogram-np.mean(log_exp_variogram))**2)\n",
    "    #And finally, the r_squared-value with,\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    return slope, slope_var, r_squared, fitted_line\n",
    "\n",
    "\n",
    "def get_fitted_line_strfunc(bins_str_func,str_func,max_bin,q):\n",
    "\n",
    "    select_bins_str_func = bins_str_func[bins_str_func<=max_bin] \n",
    "    select_str_func      = str_func[bins_str_func<=max_bin]\n",
    "\n",
    "    slope, slope_var, r_squared, fitted_line = fit_data(select_bins_str_func, select_str_func)\n",
    "    \n",
    "    label = f\"Slope = $\\\\zeta_{{{q}}}$={slope:.3f}\"# Â± {slope_var:.2e}, $R^{2}$={np.round(r_squared, 2)}'\n",
    "\n",
    "    return select_bins_str_func, fitted_line, label\n",
    "\n",
    "\n",
    "select_bins_str_func1, fitted_line_str_func1, label_str_func1 = get_fitted_line_strfunc(bins_str_func1,str_func1,140,'1')\n",
    "select_bins_vario1, fitted_line_vario1, label_vario1 = get_fitted_line_strfunc(bins1,vario1,140,'2')\n",
    "\n",
    "\n",
    "select_bins_str_func2, fitted_line_str_func2, label_str_func2 = get_fitted_line_strfunc(bins_str_func2,str_func2,30,'1')\n",
    "select_bins_vario2, fitted_line_vario2, label_vario2 = get_fitted_line_strfunc(bins2,vario2,30,'2')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "# Plot in loglog scale\n",
    "data_points1, = axes[0].loglog(bins_str_func1,str_func1, 'o', markersize=3, color='green',label='First-order SF')  # Original data (not log-transformed)\n",
    "fitted_line1, = axes[0].loglog(select_bins_str_func1, 10**fitted_line_str_func1, color='green', label='First-order SF Linear Fit; '+label_str_func1,linewidth=2.5)#f'Fitted line (y={slope1:.2f}x + {intercept:.2f})')  # Fitted line\n",
    "\n",
    "data_points1, = axes[0].loglog(bins1,vario1, 'o', markersize=3,color='#999999',label='Variogram')  # Original data (not log-transformed)\n",
    "fitted_line1, = axes[0].loglog(select_bins_vario1, 10**fitted_line_vario1, color='#999999', label='Variogram Linear Fit; '+label_vario1,linewidth=2.5)#f'Fitted line (y={slope1:.2f}x + {intercept:.2f})')  # Fitted line\n",
    "\n",
    "axes[0].legend(fontsize = 12)\n",
    "axes[0].set_xlabel('Spatial lag (km)')\n",
    "axes[0].set_ylabel('Variogram/First-Order Structure Function')# $(arbitrary-unit^{2})$')\n",
    "axes[0].set_ylim([0,1.5])\n",
    "axes[0].grid(True, which=\"both\", ls=\"--\")  # Grid for both axes in log scale\n",
    "axes[0].yaxis.set_minor_formatter(mticker.ScalarFormatter())\n",
    "#########\n",
    "\n",
    "data_points1, = axes[1].loglog(bins_str_func2,str_func2, 'o',  markersize=3, color='green',label='First-order SF')  # Original data (not log-transformed)\n",
    "fitted_line1, = axes[1].loglog(select_bins_str_func2, 10**fitted_line_str_func2, color='green',label='First-order SF '+label_str_func2,linewidth=2.5)#f'Fitted line (y={slope1:.2f}x + {intercept:.2f})')  # Fitted line\n",
    "\n",
    "data_points1, = axes[1].loglog(bins2,vario2, 'o', markersize=3, color='#999999',label='Variogram')  # Original data (not log-transformed)\n",
    "fitted_line1, = axes[1].loglog(select_bins_vario2, 10**fitted_line_vario2, color='#999999', label='Variogram '+label_vario2,linewidth=2.5)#f'Fitted line (y={slope1:.2f}x + {intercept:.2f})')  # Fitted line\n",
    "\n",
    "axes[1].legend(fontsize = 12)\n",
    "axes[1].set_xlabel('Spatial lag (km)')\n",
    "axes[1].set_ylabel('Variogram/First-Order Structure Function')# $(arbitrary-unit^{2})$')\n",
    "axes[1].set_ylim([0,1.5])\n",
    "axes[1].grid(True, which=\"both\", ls=\"--\")  # Grid for both axes in log scale\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('paper_1_new_fig1_panels_e_f.png',dpi=150,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save variograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import cartopy.crs as crs\n",
    "import random\n",
    "import skgstat as skg\n",
    "import matplotlib.ticker as ticker\n",
    "import read_vars_WRF_RAMS\n",
    "import variogram_helper_functions\n",
    "import matplotlib\n",
    "from skimage import data, filters, measure, morphology\n",
    "\n",
    "\n",
    "matplotlib.rcParams[\"font.family\"] = \"Roboto\"\n",
    "matplotlib.rcParams[\"font.sans-serif\"] = [\"Roboto\"]  # For non-unicode text\n",
    "matplotlib.rcParams['axes.labelsize'] = 18\n",
    "matplotlib.rcParams['axes.titlesize'] = 18\n",
    "matplotlib.rcParams['xtick.labelsize'] = 18\n",
    "matplotlib.rcParams['ytick.labelsize'] = 18\n",
    "matplotlib.rcParams['legend.fontsize'] = 18\n",
    " \n",
    "def save_variogram(VERSION, WHICH_TIME,MODEL_FILE,VARIABLE, SIMULATION, ENSEMBLE_NUMBER, CONDITION_INFO, SAMPLE_SIZE, BIN_WIDTH_IN_KM, DOMAIN, SAVE_CSV, ESTIMATOR='matheron',SAMPLING_STRATEGY='randomly_distributed'):\n",
    "    \"\"\"\n",
    "    VERSION: an additional string to be added to the final csv file; in this cases it is the Version# of RAMS/WRF simulations\n",
    "    WHICH_TIME: 'start','middle','end' string; grab the files corresponding to these strings\n",
    "    MODEL_FILE: path to a file; use instead of the 'WHICH_TIME' option \n",
    "    VARIABLE:    variable for which we want the variogram; it is a list containing the properties of the storm e.g., ['QV', 0, 'model', '$q_{v}$', '$kg^{2}kg^{-2}$'] \n",
    "    SIMULATION: name of the simulation\n",
    "    CONDITION_INFO:\n",
    "    SAMPLE_SIZE: # of points to be drawn from the domain \n",
    "    DOMAIN: '1' or '2' or '3'\n",
    "    SAVE_CSV: True or False; whether to save this data or not\n",
    "    ESTIMATOR='matheron': 'matheron' or 'first_order_structure_function' or 'second_order_structure_function' and so on, upto fifth order\n",
    "    \"\"\"\n",
    "    make_QTC_plot = True\n",
    "    make_variogram_for_each_storm=False\n",
    "    \n",
    "    print('working on domain' ,domain)\n",
    "    print('working on ',VARIABLE)\n",
    "    print('working on simulation: ',SIMULATION)\n",
    "    \n",
    "    # provide grid spacings in km to multiply with the variogram bin distances\n",
    "    if DOMAIN=='1':\n",
    "        dx = 1.6 # km\n",
    "    if DOMAIN=='2':\n",
    "        dx=0.4   # km\n",
    "    if DOMAIN=='3':\n",
    "        dx=0.1   # km\n",
    "        \n",
    "    # which model are we working on; need this for the read_RAMS_WRF_data_file\n",
    "    if SIMULATION[7]=='W':\n",
    "        model_name = 'WRF'\n",
    "        microphysics_scheme = SIMULATION[8]\n",
    "    elif SIMULATION[7]=='R':\n",
    "        model_name = 'RAMS'\n",
    "    else:\n",
    "        print('!!!!!issues with identifying model_name!!!!!')\n",
    "\n",
    "    print('        model name: ',model_name)\n",
    "\n",
    "    # grab the file needed\n",
    "    if WHICH_TIME:\n",
    "        if model_name=='RAMS':  \n",
    "            selected_fil = variogram_helper_functions.find_RAMS_file(SIMULATION=SIMULATION,DOMAIN=DOMAIN,WHICH_TIME=WHICH_TIME)\n",
    "\n",
    "        if model_name=='WRF':\n",
    "            selected_fil =  variogram_helper_functions.find_WRF_file(SIMULATION=SIMULATION,DOMAIN=DOMAIN,WHICH_TIME=WHICH_TIME)\n",
    "    \n",
    "    if MODEL_FILE:\n",
    "        print('a file path is provided')\n",
    "        selected_fil = MODEL_FILE\n",
    "    \n",
    "    timestring = variogram_helper_functions.get_time_from_a_file(selected_fil,model_name)[0]\n",
    "    print('time in this file = ',timestring)\n",
    "    \n",
    "    #### MAIN PART ####\n",
    "    # read the main variable \n",
    "    z, z_name, z_units, z_time = read_vars_WRF_RAMS.read_variable(selected_fil,VARIABLE[0],model_name,output_height=False,interpolate=VARIABLE[1]>-1,level=VARIABLE[1],interptype=VARIABLE[2])\n",
    "    \n",
    "    # remove 40km from the edges\n",
    "    z = variogram_helper_functions.remove_edges(z, 40.0, dx) # remove 40 km along each edge - new version\n",
    "    \n",
    "    # get the dimensions for producing list of random coordinates\n",
    "    y_dim, x_dim     = np.shape(z)\n",
    "    \n",
    "\n",
    "    if CONDITION_INFO[0]=='environment':\n",
    "        print('getting random coordinates over ',CONDITION_INFO[0],' points with threshold ',CONDITION_INFO[1])\n",
    "        #print('        getting total condensate for conditional variogram') \n",
    "        if VARIABLE[1]<0:\n",
    "            conditional_field_mask_file = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/G'+DOMAIN+'/masks/'+SIMULATION+'_'+CONDITION_INFO[0]+'_mask_QTC_threshold_'+str(CONDITION_INFO[1])+'_levtype_'+'model'+'_lev_0_'+z_time+'.npy'\n",
    "        else: \n",
    "            conditional_field_mask_file = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/G'+DOMAIN+'/masks/'+SIMULATION+'_'+CONDITION_INFO[0]+'_mask_QTC_threshold_'+str(CONDITION_INFO[1])+'_levtype_'+VARIABLE[2]+'_lev_'+str(VARIABLE[1])+'_'+z_time+'.npy'\n",
    "\n",
    "        print('reading mask file:',conditional_field_mask_file)\n",
    "        conditional_field = np.load(conditional_field_mask_file)\n",
    "        #conditional_field = variogram_helper_functions.remove_edges(conditional_field, 10.0, dx) - old version\n",
    "        conditional_field = variogram_helper_functions.remove_edges(conditional_field, 40.0, dx) #- new version\n",
    "        print('        min, max for the condensate field is ',np.min(conditional_field),' ',np.max(conditional_field))\n",
    "\n",
    "        coords = variogram_helper_functions.produce_random_coords_conditional(SAMPLE_SIZE, conditional_field, CONDITION_STATEMENT=lambda x: x > -100)\n",
    "        max_lag          = np.sqrt(x_dim**2 + y_dim**2)/2.0# in grid points\n",
    "        \n",
    "        \n",
    "        #------- PLOT QTC FIELD ---------#\n",
    "        # create total condensate plot\n",
    "        \n",
    "        if make_QTC_plot:\n",
    "            savepng = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/'+'G'+DOMAIN+'/PNGs/'\n",
    "            if not os.path.exists(savepng):\n",
    "                os.makedirs(savepng)\n",
    "\n",
    "            fig, ax = plt.subplots(1,figsize=(9,9))\n",
    "            #qtc_field_contours = ax.imshow(conditional_field)\n",
    "            qtc_field_contours = ax.imshow(z)\n",
    "\n",
    "            y_coords, x_coords = zip(*coords)\n",
    "            ax.scatter(np.array(x_coords), np.array(y_coords), color='red', marker='o',s=.07)\n",
    "            plt.title('random pts (env) at level '+str(VARIABLE[1])+'\\n'+z_time)\n",
    "            plt.colorbar(qtc_field_contours)\n",
    "            plt.savefig(savepng+'publication_40km_edges_'+VARIABLE[0]+'_levtype_'+VARIABLE[2]+'_lev_'+str(VARIABLE[1])+'_ensemble_'+str(ENSEMBLE_NUMBER)+'_QTC_field_environment_points_'+SIMULATION+'_'+z_time+'.png')\n",
    "            plt.close()\n",
    "\n",
    "    if CONDITION_INFO[0]=='storm': \n",
    "        print('getting random coordinates over ',CONDITION_INFO[0],' points with threshold ',CONDITION_INFO[1])\n",
    "        print('        getting total condensate for conditional variogram')\n",
    "        \n",
    "        if VARIABLE[1]<0:\n",
    "            conditional_field, _, _, _ = read_vars_WRF_RAMS.read_variable(selected_fil,'QTC',model_name,output_height=False,interpolate=True,level=0,interptype='model')\n",
    "            #conditional_field          = variogram_helper_functions.remove_edges(conditional_field, 10.0, dx)\n",
    "            conditional_field          = variogram_helper_functions.remove_edges(conditional_field, 40.0, dx)\n",
    "        else:\n",
    "            conditional_field, _, _, _ = read_vars_WRF_RAMS.read_variable(selected_fil,'QTC',model_name,output_height=False,interpolate=VARIABLE[1]>-1,level=VARIABLE[1],interptype=VARIABLE[2])\n",
    "            #conditional_field          = variogram_helper_functions.remove_edges(conditional_field, 10.0, dx)\n",
    "            conditional_field          = variogram_helper_functions.remove_edges(conditional_field, 40.0, dx)\n",
    "        \n",
    "        print('size of conditional field ',np.shape(conditional_field))\n",
    "        # regionprops part\n",
    "        # using region props to delineate storm objects\n",
    "        img      = conditional_field\n",
    "        mask     = img > CONDITION_INFO[1]\n",
    "        mask     = morphology.remove_small_objects(mask, 32)\n",
    "        #mask    = morphology.remove_small_holes(mask, 10)\n",
    "        labels   = measure.label(mask)\n",
    "        props    = measure.regionprops(labels, img)\n",
    "        if len(props)==0:\n",
    "            print('regionprops could not find any storm !!!\\n\\n\\n')\n",
    "            coords = []\n",
    "        else:\n",
    "            major_axis_length_list = []\n",
    "            \n",
    "            for index in range(1, labels.max()):\n",
    "                major_axis_length_list.append(getattr(props[index], 'major_axis_length'))\n",
    "                \n",
    "                if make_variogram_for_each_storm:\n",
    "                    print('estimating variogram for storm#',index)\n",
    "                    max_lag_storm          = getattr(props[index], 'major_axis_length')/2.0\n",
    "                    print('using maximum lag',max_lag_storm,' grid points')\n",
    "                    coords_storm = props[index].coords\n",
    "                    print('size of this storm = ',len(coords_storm))\n",
    "                    #print('coordinates of this storm are: ',coords_storm)\n",
    "                    #rows = [uu[0] for uu in chosen_area_label_coords_array]\n",
    "                    #cols = [uu[1] for uu in chosen_area_label_coords_array]\n",
    "                    #storm_mask_nans = np.zeros_like(img)*np.nan  # *np.nan\n",
    "                    #storm_mask_nans[rows, cols] = 1.0\n",
    "                    nonnan_coords_storm, nonnan_values_storm = variogram_helper_functions.get_values_at_random_coords(z, coords_storm)\n",
    "                    num_lag_classses_storm = int(max_lag_storm*dx/BIN_WIDTH_IN_KM)\n",
    "                    # create a variogram and save bin and variogram values in a matrix for saving\n",
    "                    V_storm , bins_storm, exp_variogram_storm            = variogram_helper_functions.make_variogram(nonnan_coords_storm, nonnan_values_storm,num_lag_classses_storm,MAXLAG=max_lag_storm,DX=dx,ESTIMATOR=ESTIMATOR)\n",
    "                    bins_middle_points_storm, counts_storm, widths_storm = variogram_helper_functions.retrieve_histogram(V_storm,DX=dx)\n",
    "                    ##########################################################################################\n",
    "                    # plot the coordinates used to make variogram for this storm object\n",
    "                    savepng = '/home/isingh/code/variogram_data/'+SIMULATION+'/'+'G'+DOMAIN+'/PNGs/'\n",
    "                    fig, ax = plt.subplots(1,figsize=(9,9))\n",
    "                    z_field_contours = ax.imshow(z)\n",
    "                    label_i = props[index].label\n",
    "                    contour = measure.find_contours(labels == label_i, 0.5)[0]\n",
    "                    y, x = contour.T\n",
    "                    ax.plot(x, y, linewidth=1.0, color = 'k') # Plot the contour lines\n",
    "                    y_coords_storm, x_coords_storm = zip(*coords_storm)\n",
    "                    ax.scatter(np.array(x_coords_storm), np.array(y_coords_storm), color='red', marker='o',s=.07)\n",
    "                    plt.title(VARIABLE[0]+ '('+VARIABLE[4]+') with random pts (storm#'+str(index)+')'+'\\n'+z_time)\n",
    "                    plt.colorbar(z_field_contours)\n",
    "                    plt.savefig(savepng+'publication_'+VARIABLE[0]+'_storm_object'+str(index)+SIMULATION+'_'+z_time+'.png')\n",
    "                    plt.close()\n",
    "                    ##########################################################################################\n",
    "                    if SAVE_CSV:\n",
    "                        savecsv = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/'+'G'+DOMAIN+'/CSVs'\n",
    "                        if not os.path.exists(savecsv):\n",
    "                            os.makedirs(savecsv)\n",
    "                        if VARIABLE[2]:\n",
    "                            data_file_storm = savecsv+'/publication_individual_storm_'+str(index)+'_experimental_variogram_'+SAMPLING_STRATEGY+'_sampling_'+str(SAMPLE_SIZE)+'_samples_binwidth_'+str(int(BIN_WIDTH_IN_KM))+'km_estimator_'+ESTIMATOR+'_'+'_'+SIMULATION+'_G'+DOMAIN+'_'+CONDITION_INFO[0]+'_points_threshold_'+str(CONDITION_INFO[1])+'_'+VARIABLE[0]+'_levtype_'+VARIABLE[2]+'_lev_'+str(int(VARIABLE[1]))+'_'+z_time+'.csv'\n",
    "                        else:\n",
    "                            data_file_storm = savecsv+'/publication_individual_storm_'+str(index)+'_experimental_variogram_'+SAMPLING_STRATEGY+'_sampling_'+str(SAMPLE_SIZE)+'_samples_binwidth_'+str(int(BIN_WIDTH_IN_KM))+'km_estimator_'+ESTIMATOR+'_'+'_'+SIMULATION+'_G'+DOMAIN+'_'+CONDITION_INFO[0]+'_points_threshold_'+str(CONDITION_INFO[1])+'_'+VARIABLE[0]+'_levtype_'+'None'+'_lev_'+'None'+'_'+z_time+'.csv'\n",
    "\n",
    "                        data_matrix_storm = np.column_stack((bins_storm, counts_storm, widths_storm, exp_variogram_storm))\n",
    "                        np.savetxt(data_file_storm, data_matrix_storm, delimiter=',', header='bins,counts,widths,exp_variogram', comments='')\n",
    "            ######################################################\n",
    "          \n",
    "            #print('list of all major lenth axes in gridpoints: ',major_axis_length_list)\n",
    "            print('max length of a storm object in gridpoints = ',max(major_axis_length_list))\n",
    "            print('max length in km = ',max(major_axis_length_list)*dx)\n",
    "\n",
    "            max_lag          = max(major_axis_length_list)/2.0# in grid points\n",
    "            #--------------------------------------------------\n",
    "            print('        min, max for the condensate field is ',np.min(conditional_field),' ',np.max(conditional_field))\n",
    "            coords = variogram_helper_functions.produce_random_coords_conditional(SAMPLE_SIZE, conditional_field, CONDITION_STATEMENT=lambda x: x >= CONDITION_INFO[1])\n",
    "        #------- PLOT QTC FIELD ---------#\n",
    "        # create total condensate plot\n",
    "        if make_QTC_plot:\n",
    "            savepng = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/'+'G'+DOMAIN+'/PNGs/'\n",
    "            if not os.path.exists(savepng):\n",
    "                os.makedirs(savepng)\n",
    "                \n",
    "            fig, ax = plt.subplots(1,figsize=(9,9))\n",
    "            qtc_field_contours = ax.imshow(conditional_field)\n",
    "\n",
    "            if len(props)>0:\n",
    "                for index in range(1, labels.max()):\n",
    "                        major_axis_length_list.append(getattr(props[index], 'major_axis_length'))\n",
    "                        label_i = props[index].label\n",
    "                        contour = measure.find_contours(labels == label_i, 0.5)[0]\n",
    "                        # Plot the contour lines\n",
    "                        y, x = contour.T\n",
    "                        ax.plot(x, y, linewidth=1.0)\n",
    "\n",
    "                y_coords, x_coords = zip(*coords)\n",
    "                ax.scatter(np.array(x_coords), np.array(y_coords), color='red', marker='o',s=.07)\n",
    "\n",
    "            plt.title('QTC field (kg/kg) with random pts (storm)'+'\\n'+z_time)\n",
    "            plt.colorbar(qtc_field_contours)\n",
    "            plt.savefig(savepng+'publication_40km_edges_'+VARIABLE[0]+'_ensemble_'+str(ENSEMBLE_NUMBER)+'_QTC_field_storm_points_'+SIMULATION+'_'+z_time+'.png')\n",
    "            plt.close()\n",
    "        \n",
    "    if CONDITION_INFO[0]=='all':\n",
    "        print('getting random coordinates over ',CONDITION_INFO[0],' points')\n",
    "        coords = variogram_helper_functions.produce_random_coords(x_dim,y_dim,SAMPLE_SIZE,SAMPLING_STRATEGY)   \n",
    "        max_lag          = np.sqrt(x_dim**2 + y_dim**2)/2.0# in grid points\n",
    "                \n",
    "    ###########  VARIOGRAM ESTIMATION ##########   \n",
    "    # get the values of the field at the random coordinates\n",
    "    if len(coords)>0:\n",
    "        nonnan_coords, nonnan_values = variogram_helper_functions.get_values_at_random_coords(z, coords)\n",
    "        num_lag_classses = int(max_lag*dx/BIN_WIDTH_IN_KM)\n",
    "        # create a variogram and save bin and variogram values in a matrix for saving\n",
    "        V , bins, exp_variogram = variogram_helper_functions.make_variogram(nonnan_coords, nonnan_values,num_lag_classses,MAXLAG=max_lag,DX=dx,ESTIMATOR=ESTIMATOR)\n",
    "        print('        using bin width = ',BIN_WIDTH_IN_KM,' km')\n",
    "        bins_middle_points, counts, widths = variogram_helper_functions.retrieve_histogram(V,DX=dx)\n",
    "    else:\n",
    "        V                  = -999\n",
    "        bins               = -999\n",
    "        exp_variogram      = -999\n",
    "        bins_middle_points = -999\n",
    "        counts             = -999\n",
    "        widths             = -999\n",
    "        ##########################\n",
    "\n",
    "    if SAVE_CSV:\n",
    "        savecsv = '/home/isingh/code/variogram_data/'+VERSION+'/'+SIMULATION+'/'+'G'+DOMAIN+'/CSVs/'\n",
    "        \n",
    "        if not os.path.exists(savecsv):\n",
    "            os.makedirs(savecsv)\n",
    "            \n",
    "        if VARIABLE[2]:\n",
    "            data_file = savecsv+'publication_40km_edge_experimental_variogram_ensemble_'+str(ENSEMBLE_NUMBER)+'_'+SAMPLING_STRATEGY+'_sampling_'+str(SAMPLE_SIZE)+'_samples_binwidth_'+str(int(BIN_WIDTH_IN_KM))+'km_estimator_'+ESTIMATOR+'_'+SIMULATION+'_G'+DOMAIN+'_'+CONDITION_INFO[0]+'_points_threshold_'+str(CONDITION_INFO[1])+'_'+VARIABLE[0]+'_levtype_'+VARIABLE[2]+'_lev_'+str(int(VARIABLE[1]))+'_'+z_time+'.csv'\n",
    "        else:\n",
    "            data_file = savecsv+'publication_40km_edge_experimental_variogram_ensemble_'+str(ENSEMBLE_NUMBER)+'_'+SAMPLING_STRATEGY+'_sampling_'+str(SAMPLE_SIZE)+'_samples_binwidth_'+str(int(BIN_WIDTH_IN_KM))+'km_estimator_'+ESTIMATOR+'_'+SIMULATION+'_G'+DOMAIN+'_'+CONDITION_INFO[0]+'_points_threshold_'+str(CONDITION_INFO[1])+'_'+VARIABLE[0]+'_levtype_'+'None'+'_lev_'+'None'+'_'+z_time+'.csv'\n",
    "\n",
    "        data_matrix = np.column_stack((bins, counts, widths, exp_variogram))\n",
    "        np.savetxt(data_file, data_matrix, delimiter=',', header='bins,counts,widths,exp_variogram', comments='')\n",
    "\n",
    "        print('        saving variogram data to ',data_file)\n",
    "        #print('    ------\\n')\n",
    "    return #bins_middle_points, exp_variogram, coords\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "variables= [\n",
    "            ['WSPD'  , 0   , 'model'   , '$wspd$'       , '$m^{2}s^{-2}$']   ,\n",
    "            ['QV'    , 0   , 'model'   , '$q_{v}$'      , '$kg^{2}kg^{-2}$'] ,\n",
    "            ['Tk'    , 0   , 'model'   , '$temperature$', '$K^{2}$']         ,\n",
    "            ['WSPD'  , 750 , 'pressure', '$wspd$'       , '$m^{2}s^{-2}$']   ,\n",
    "            ['QV'    , 750 , 'pressure', '$q_{v}$'      , '$kg^{2}kg^{-2}$'] ,\n",
    "            ['Tk'    , 750 , 'pressure', '$temperature$', '$K^{2}$']         , \n",
    "            ['WSPD'  , 500 , 'pressure', '$wspd$'       , '$m^{2}s^{-2}$']   ,\n",
    "            ['QV'    , 500 , 'pressure', '$q_{v}$'      , '$kg^{2}kg^{-2}$'] ,\n",
    "            ['Tk'    , 500 , 'pressure', '$temperature$', '$K^{2}$']         \n",
    "           ]\n",
    "\n",
    "#variables= [['MCAPE'   , -999,  'model'     , '$MCAPE$'        , '$J^{2}kg^{-2}$'] ,]\n",
    "#             ['SHF'   , -999,  'model'     , '$SHF$'        , '$W^{2}m^{-4}$'] ,\n",
    "#             ['LHF'   , -999,  'model'     , '$LHF$'        , '$W^{2}m^{-4}$'] ,\n",
    "#            ]      \n",
    "     \n",
    "domain='1'\n",
    "colors      = ['#000000','#377eb8', '#56B4E9','#ff7f00', '#4daf4a','#f781bf', '#a65628', '#984ea3','#999999', '#e41a1c', '#dede00']\n",
    "simulations = ['PHI2.1-R','PHI1.1-R','AUS1.1-R','USA1.1-R','WPO1.1-R','BRA1.1-R','BRA1.2-R','RSA1.1-R','ARG1.1-R','ARG1.2-R','DRC1.1-R']\n",
    "thresholds  = [0.0000001,]\n",
    "estimators  = ['matheron',]#'first_order_structure_function','second_order_structure_function','third_order_structure_function','fourth_order_structure_function','fifth_order_structure_function',]\n",
    "#n',]#,\n",
    "partitions  = ['environment',] #'storm','all'\n",
    "sampling_strategy = 'randomly_distributed'\n",
    "bin_widths  = [5.0,]\n",
    "sample_sizes = [20000,]\n",
    "ensembles = np.arange(1,2,1)\n",
    "print('# ensembles:',ensembles)\n",
    "\n",
    "file_dict = {'PHI2.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/PHI2.1-R-V0/G3/out_30s/a-A-2019-09-10-153000-g'+domain+'.h5',\n",
    "             'PHI1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/PHI1.1-R-V0/G3/out_30s/a-A-2019-09-10-120000-g'+domain+'.h5',\n",
    "             'AUS1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/AUS1.1-R-V0/G3/out_30s/a-A-2006-01-23-120000-g'+domain+'.h5',\n",
    "             'USA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/USA1.1-R-V0/G3/out_30s/a-A-2022-09-16-110000-g'+domain+'.h5',\n",
    "             'WPO1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/WPO1.1-R-V0/G3/out_30s/a-A-2018-08-28-065000-g'+domain+'.h5',\n",
    "             'BRA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/BRA1.1-R-V0/G3/out_30s/a-A-2014-03-31-190000-g'+domain+'.h5',\n",
    "             'BRA1.2-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/BRA1.2-R-V0/G3/out_30s/a-A-2014-04-01-140000-g'+domain+'.h5',\n",
    "             'RSA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/RSA1.1-R-V0/G3/out_30s/a-A-2008-03-11-123000-g'+domain+'.h5',\n",
    "             'ARG1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/ARG1.1-R-V0/G3_old/out_30s/a-A-2018-12-13-210000-g'+domain+'.h5',\n",
    "             'ARG1.2-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/ARG1.2-R-V0/G3/out_30s/a-A-2018-12-14-013000-g'+domain+'.h5',\n",
    "             'DRC1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/DRC1.1-R-V0/G3/out_30s/a-A-2016-12-30-113000-g'+domain+'.h5'}\n",
    "\n",
    "# run with one core in serial\n",
    "#save_variogram('V0',None,'/monsoon/MODEL/LES_MODEL_DATA/V0/DRC1.1-R-V0/G3/out_30s/a-A-2016-12-30-113000-g1.h5',variables[0],'DRC1.1-R', ['storm',0.0000001], 5000, 5.0, '1', True, 'matheron')\n",
    "\n",
    "#Running on the terminal in parallel\n",
    "argument = []\n",
    "\n",
    "for simulation in simulations:\n",
    "    for variable in variables:\n",
    "        for partition in partitions:\n",
    "            for threshold in thresholds:\n",
    "                for estimator in estimators:\n",
    "                    for bin_width in bin_widths:\n",
    "                        for sample_size in sample_sizes:\n",
    "                            for ensemble_member in ensembles:\n",
    "                                argument = argument + [('V0', None, file_dict[simulation], variable, simulation,ensemble_member, [partition, threshold] , sample_size, bin_width, domain, True, estimator)]\n",
    "\n",
    "print('length of argument is: ',len(argument))\n",
    "for element in argument:\n",
    "    print(element)\n",
    "############################### FIRST OF ALL ################################\n",
    "cpu_count1 = 16 #cpu_count()\n",
    "print('number of cpus: ',cpu_count1)\n",
    "# # #############################################################################\n",
    "\n",
    "def main(FUNCTION, ARGUMENT):\n",
    "    start_time = time.perf_counter()\n",
    "    with Pool(processes = (cpu_count1)) as pool:\n",
    "        data = pool.starmap(FUNCTION, ARGUMENT)\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"Program finished in {finish_time-start_time} seconds\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main(save_variogram, argument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit variogram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from skgstat.models import spherical, exponential, gaussian, cubic\n",
    "import matplotlib.ticker as ticker\n",
    "import variogram_helper_functions\n",
    "\n",
    "matplotlib.rcParams[\"font.family\"] = \"Roboto\"\n",
    "matplotlib.rcParams[\"font.sans-serif\"] = [\"Roboto\"]  # For non-unicode text\n",
    "matplotlib.rcParams['axes.labelsize'] = 25\n",
    "matplotlib.rcParams['axes.titlesize'] = 20\n",
    "matplotlib.rcParams['xtick.labelsize'] = 10\n",
    "matplotlib.rcParams['ytick.labelsize'] = 25\n",
    "matplotlib.rcParams['legend.fontsize'] = 25\n",
    "matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "\n",
    "simulations = ['ARG1.1-R', 'ARG1.2-R', 'PHI2.1-R', 'AUS1.1-R', 'DRC1.1-R', 'PHI1.1-R', 'USA1.1-R', 'WPO1.1-R', 'BRA1.1-R', 'BRA1.2-R', 'RSA1.1-R']\n",
    "\n",
    "# List of variables with different names and levels\n",
    "variables= [\n",
    "             ['WSPD'  , 0   , 'model'   , '$wspd$'       , '$m^{2}s^{-2}$']   ,]\n",
    "             ['QV'    , 0   , 'model'   , '$q_{v}$'      , '$kg^{2}kg^{-2}$'] ,\n",
    "             ['Tk'    , 0   , 'model'   , '$temperature$', '$K^{2}$']         ,\n",
    "             ['WSPD'  , 500 , 'pressure', '$wspd$'       , '$m^{2}s^{-2}$']   ,\n",
    "             ['QV'    , 500 , 'pressure', '$q_{v}$'      , '$kg^{2}kg^{-2}$'] ,\n",
    "             ['Tk'    , 500 , 'pressure', '$temperature$', '$K^{2}$']         ,\n",
    "             ['MCAPE' , -999,  'model'  , '$MCAPE$'      , '$J^{2}kg^{-2}$']  ,\n",
    "             ['SHF'   , -999,  'model'  , '$SHF$'        , '$W^{2}m^{-4}$']   ,\n",
    "             ['LHF'   , -999,  'model'  , '$SHF$'        , '$W^{2}m^{-4}$']   ,\n",
    "           ]\n",
    "\n",
    "\n",
    "\n",
    "def linear(h, r, c0, b=0):\n",
    "    return b + c0 * (h)\n",
    "\n",
    "def power(h, r, c0, b=0):\n",
    "    return b + c0 * (h**r)\n",
    "\n",
    "def sph_exp(h,a1,b1,a2,b2):\n",
    "    return spherical(h, a1, b1) + exponential(h, a2, b2)\n",
    "\n",
    "def gau_sph(h,a1,b1,a2,b2):\n",
    "    return gaussian(h, a1, b1)  + spherical(h, a2, b2)\n",
    "\n",
    "def exp_gau(h,a1,b1,a2,b2):\n",
    "    return exponential(h, a1, b1)  + gaussian(h, a2, b2)\n",
    "\n",
    "curve_fitting_fs = {\n",
    "    'gaussian': lambda h, a, b: gaussian(h, a, b),\n",
    "    'exponential': lambda h, a, b: exponential(h, a, b),\n",
    "    'spherical': lambda h, a, b: spherical(h, a, b),\n",
    "    'cubic': lambda h, a, b: cubic(h, a, b),\n",
    "    'power': lambda h, a, b: power(h, a, b),\n",
    "    'sph_exp':lambda h, a1, b1, a2, b2: spherical(h, a1, b1) + exponential(h, a2, b2),\n",
    "    'exp_gau':lambda h, a1, b1, a2, b2: exponential(h, a1, b1) + gaussian(h, a2, b2),\n",
    "}\n",
    "\n",
    "theoretical_fits = {\n",
    "    'gaussian': gaussian,\n",
    "    'exponential': exponential,\n",
    "    'spherical': spherical,\n",
    "    'cubic': cubic,\n",
    "    'power': power,\n",
    "    'sph_exp':sph_exp,\n",
    "    'exp_gau':exp_gau,\n",
    "}\n",
    "\n",
    "domain = '1'\n",
    "version='V0'\n",
    "\n",
    "file_dict = {'PHI2.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/PHI2.1-R-V0/G3/out_30s/a-A-2019-09-10-153000-g'+domain+'.h5',\n",
    "             'PHI1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/PHI1.1-R-V0/G3/out_30s/a-A-2019-09-10-120000-g'+domain+'.h5',\n",
    "             'AUS1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/AUS1.1-R-V0/G3/out_30s/a-A-2006-01-23-120000-g'+domain+'.h5',\n",
    "             'USA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/USA1.1-R-V0/G3/out_30s/a-A-2022-09-16-110000-g'+domain+'.h5',\n",
    "             'WPO1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/WPO1.1-R-V0/G3/out_30s/a-A-2018-08-28-065000-g'+domain+'.h5',\n",
    "             'BRA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/BRA1.1-R-V0/G3/out_30s/a-A-2014-03-31-190000-g'+domain+'.h5',\n",
    "             'BRA1.2-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/BRA1.2-R-V0/G3/out_30s/a-A-2014-04-01-140000-g'+domain+'.h5',\n",
    "             'RSA1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/RSA1.1-R-V0/G3/out_30s/a-A-2008-03-11-123000-g'+domain+'.h5',\n",
    "             'ARG1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/ARG1.1-R-V0/G3_old/out_30s/a-A-2018-12-13-210000-g'+domain+'.h5',\n",
    "             'ARG1.2-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/ARG1.2-R-V0/G3/out_30s/a-A-2018-12-14-013000-g'+domain+'.h5',\n",
    "             'DRC1.1-R':'/monsoon/MODEL/LES_MODEL_DATA/V0/DRC1.1-R-V0/G3/out_30s/a-A-2016-12-30-113000-g'+domain+'.h5'}\n",
    "\n",
    "cmaps_dict = {'QV':['viridis','red'],'THETAV':['viridis','red'],'Tk':['viridis','red'],'WSPD':['viridis','red'],'W':['viridis','red'],'MCAPE':['viridis','red'],\\\n",
    "             'ITC':['viridis','red'],'SHF':['viridis','red'],'LHF':['viridis','red'],'SHF':['viridis','red'],'PCP_ACC':['viridis','red']}\n",
    "\n",
    "condition_info = ['environment',1e-07]\n",
    "#'linear': linear,\n",
    "#'gau_sph':gau_sph,\n",
    "# DataFrame to store results with columns for each variable's effective range and selected variogram\n",
    "results_df = pd.DataFrame(index=simulations)\n",
    "\n",
    "# Flag to control plotting\n",
    "plot_figures = True  # Set to True to enable plotting\n",
    "\n",
    "for var in variables:\n",
    "    var_name = var[0]  # e.g., SHF, LHF, WSPD\n",
    "    level = var[1]     # e.g., -999, 0, 500\n",
    "    col_range_name = f\"{var_name}_{level}_effective_range\"  # Column for effective range\n",
    "    col_model_name = f\"{var_name}_{level}_selected_model\"   # Column for selected variogram model\n",
    "    results_df[col_range_name] = np.nan  # Initialize column for effective range\n",
    "    results_df[col_model_name] = None  # Initialize column for selected model\n",
    "    \n",
    "    var_units = var[4]\n",
    "\n",
    "    for sim in simulations:\n",
    "        print('================ SIMULATION ================= ', sim)\n",
    "        \n",
    "        ###########################\n",
    "        z_time = variogram_helper_functions.get_time_from_RAMS_file(file_dict[sim])[1]\n",
    "        if var[1]<0:\n",
    "            conditional_field_mask_file = '/home/isingh/code/variogram_data/'+version+'/'+sim+'/G'+domain+'/masks/'+sim+'_'+condition_info[0]+'_mask_QTC_threshold_'+str(condition_info[1])+'_levtype_'+'model'+'_lev_0_'+z_time+'.npy'\n",
    "        else: \n",
    "            conditional_field_mask_file = '/home/isingh/code/variogram_data/'+version+'/'+sim+'/G'+domain+'/masks/'+sim+'_'+condition_info[0]+'_mask_QTC_threshold_'+str(condition_info[1])+'_levtype_'+var[2]+'_lev_'+str(var[1])+'_'+z_time+'.npy'\n",
    "        \n",
    "        env_mask = np.load(conditional_field_mask_file)\n",
    "        \n",
    "        cmap = cmaps_dict[var[0]][0]\n",
    "        \n",
    "        variogram_helper_functions.make_plan_view_RAMS_WRF(file_dict, var, sim, '1', cmap, 15000, False, env_mask, )\n",
    "        ###########################\n",
    "        \n",
    "        if plot_figures:\n",
    "            fig = plt.figure(figsize=(9, 9))\n",
    "            ax = plt.gca()\n",
    "\n",
    "        vario_files = sorted(glob.glob('/home/isingh/code/variogram_data/V0/' + sim + '/G1/CSVs/publication_experimental_variogram_ensemble_1_randomly_distributed_sampling_20000_samples_binwidth_5km_estimator_*matheron*_G1_environment_points_threshold_1e-07_' + var_name + '_levtype_' + var[2] + '_lev_' + str(level) + '_*.csv'))\n",
    "        print('found file: ', vario_files)\n",
    "        best_rmse = np.inf\n",
    "        best_range = None\n",
    "        best_model = None\n",
    "\n",
    "        for csv_file in vario_files:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            #print(df)\n",
    "\n",
    "            x_orig = df.bins.values\n",
    "            y_orig = df.exp_variogram.values\n",
    "            x = x_orig#[x_orig<=100.]\n",
    "            y = y_orig#[x_orig<=100.]\n",
    "            #X = np.asarray([(_ + 1) for _ in x])\n",
    "            sigma = None#np.exp(1. / X)\n",
    "            #\n",
    "            \n",
    "            xi = x\n",
    "            \n",
    "            if var[0] == 'QV':\n",
    "                y=y*1000.*1000.\n",
    "                var_units = '$g^{2}kg^{-2}$'\n",
    "\n",
    "            if plot_figures:\n",
    "                plt.plot(x, y, '-o', label='experimental variogram')\n",
    "\n",
    "            for fit_name, fit_function in theoretical_fits.items():\n",
    "                print('theoretical fit : ', fit_name)\n",
    "                if fit_name == 'power':\n",
    "                    param_bounds = ([0, 0], [np.inf, 2])\n",
    "                    cof, cov = curve_fit(curve_fitting_fs[fit_name], x, y, sigma=sigma,bounds=param_bounds)\n",
    "                elif fit_name in ['sph_exp','gau_sph','exp_gau']:\n",
    "                    param_bounds = ([0, 0, 0, 0], [np.max(x), np.max(y), np.max(x), np.max(y)])\n",
    "                    cof, cov = curve_fit(curve_fitting_fs[fit_name], x, y, sigma=sigma,bounds=param_bounds)\n",
    "                else:\n",
    "                    cof, cov = curve_fit(curve_fitting_fs[fit_name], x, y,sigma=sigma, bounds=(0, (np.max(x), np.max(y))))\n",
    "                \n",
    "                yi = list(map(lambda x: fit_function(x, *cof), xi))\n",
    "                rmse_c = np.sum((y - yi) ** 2)\n",
    "\n",
    "                # Handle labels for combination models\n",
    "                if fit_name in ['sph_exp', 'gau_sph','exp_gau']:\n",
    "                    vario_range_a1 = np.round(cof[0], 1)  # First range (a1)\n",
    "                    vario_range_a2 = np.round(cof[2], 1)  # Second range (a2)\n",
    "                    vario_range = f\"{vario_range_a1}, {vario_range_a2}\"  # Combine ranges\n",
    "                    \n",
    "                    if vario_range_a1>0.90*max(x):\n",
    "                        vario_range_a1 = np.nan\n",
    "                    if vario_range_a2>0.90*max(x):\n",
    "                        vario_range_a2 = np.nan\n",
    "                    \n",
    "                    # min([vario_range_a1,vario_range_a2])\n",
    "                elif fit_name == 'linear' or fit_name == 'power':\n",
    "                    vario_range = np.nan\n",
    "                else:\n",
    "                    vario_range = np.round(cof[0], 1)\n",
    "                    if vario_range>0.90*max(x):\n",
    "                        vario_range = np.nan\n",
    "\n",
    "                if fit_name == best_model:\n",
    "                    label_text = fit_name + ' - range=' + str(vario_range) + ' km; rmse=' + \"{:.1e}\".format(rmse_c) + ' units'\n",
    "                    # Add the plot with bold label for the selected model\n",
    "                    plt.plot(xi, yi, label=label_text, linewidth=2.5, color='black')\n",
    "                else:\n",
    "                    label_text = fit_name + ' - range=' + str(vario_range) + ' km; rmse=' + \"{:.1e}\".format(rmse_c) + ' units'\n",
    "                    # Add the plot with regular label for other models\n",
    "                    plt.plot(xi, yi, label=label_text)\n",
    "\n",
    "                if rmse_c < best_rmse:\n",
    "                    best_rmse = rmse_c\n",
    "                    best_range = vario_range\n",
    "                    best_model = fit_name\n",
    "\n",
    "                print('coefficients are ', *cof)\n",
    "                print('RMSE constrained for ' + fit_name + ' function:   %.2f' % rmse_c)\n",
    "\n",
    "        # Store the best effective range and the best model for this variable and simulation\n",
    "        results_df.loc[sim, col_range_name] = best_range\n",
    "        results_df.loc[sim, col_model_name] = best_model\n",
    "        \n",
    "        \n",
    "        if plot_figures:\n",
    "            # In the legend section, specify the font properties for bold text:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            legend_labels = []\n",
    "            for label in labels:\n",
    "                if best_model in label:\n",
    "                    legend_labels.append(label)  # Use this to identify the selected model\n",
    "                else:\n",
    "                    legend_labels.append(label)\n",
    "\n",
    "            # Set bold for the selected model in the legend\n",
    "            legend = plt.legend(handles=handles, labels=legend_labels, loc='lower right', fontsize=12)\n",
    "            for text in legend.get_texts():\n",
    "                if best_model in text.get_text():\n",
    "                    text.set_fontweight('bold')  # Bold the selected model's label\n",
    "            plt.xlabel('lag distance (km)')\n",
    "            plt.ylabel('Variogram')\n",
    "            \n",
    "            if var[1]>=0:\n",
    "                plt.title('Variogram for ' + sim + '\\n' + var[3] + ' at ' + var[2] + ' level ' + str(level) + ' (' + var[4] + ')')\n",
    "            else:\n",
    "                plt.title('Variogram for ' + sim + '\\n' + var[3] + ' (' + var[4] + ')')\n",
    "                \n",
    "            intervals = 60\n",
    "            # Changing tick frequencies\n",
    "            ax.xaxis.set_major_locator(ticker.MultipleLocator(intervals))\n",
    "            plt.xlim([0,max(x)])\n",
    "            plt.grid()\n",
    "            \n",
    "            png_filename = 'theoretical_model_fit_'+sim+'_'+var[0]+'_'+var[2]+'_level_' + str(level)+'.png'\n",
    "            print('saving to png ',png_filename)\n",
    "            #plt.savefig(png_filename,dpi=150)\n",
    "            #plt.close()\n",
    "            \n",
    "        print('------------------------\\n\\n')\n",
    "\n",
    "# Output the final DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute structure function exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"font.family\"]      = \"Roboto\"\n",
    "matplotlib.rcParams[\"font.sans-serif\"]  = [\"Roboto\"]  # For non-unicode text\n",
    "matplotlib.rcParams['axes.labelsize']   = 25\n",
    "matplotlib.rcParams['axes.titlesize']   = 20\n",
    "matplotlib.rcParams['xtick.labelsize']  = 25\n",
    "matplotlib.rcParams['ytick.labelsize']  = 25\n",
    "matplotlib.rcParams['legend.fontsize']  = 25\n",
    "matplotlib.rcParams['legend.facecolor'] = 'w'\n",
    "\n",
    "\n",
    "colors_dict = {'PHI2.1-R':['#999999','-'],\n",
    "               'PHI1.1-R':['#999999','--'],\n",
    "               'AUS1.1-R':['#56B4E9','-'],\n",
    "               'USA1.1-R':['#ff7f00','-'],\n",
    "               'WPO1.1-R':['#4daf4a','-'],\n",
    "               'BRA1.1-R':['#000000','-'],\n",
    "               'BRA1.2-R':['#000000','--'],\n",
    "               'RSA1.1-R':['#984ea3','-'],\n",
    "               'ARG1.1-R':['#a65628','-'],\n",
    "               'ARG1.2-R':['#a65628','--'],\n",
    "               'DRC1.1-R':['#dede00','-'] } #,\n",
    "\n",
    "simulations = ['PHI2.1-R','AUS1.1-R','DRC1.1-R','PHI1.1-R','USA1.1-R','WPO1.1-R','BRA1.1-R','BRA1.2-R','RSA1.1-R','ARG1.1-R','ARG1.2-R']\n",
    "vertical_offset = 0.1\n",
    "orders = ['first','second','third','fourth','fifth',]\n",
    "df_slope = pd.DataFrame(index=simulations, columns=orders)\n",
    "df_error = pd.DataFrame(index=simulations, columns=orders)\n",
    "\n",
    "varrs =    [['WSPD'  , 500 , 'pressure', '$wspd$' ,'$m^{2}s^{-2}$']  ,]#['WSPD'  , 0   , 'model'   , '$wspd$'       , '$m^{2}s^{-2}$'] ,]\n",
    "for var in varrs:\n",
    "    for order in orders:\n",
    "        fig = plt.figure(figsize=(9,9))\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        handles = []\n",
    "        \n",
    "        for ii, sim in enumerate(simulations):\n",
    "             \n",
    "            df_list = []\n",
    "\n",
    "            vario_files = sorted(glob.glob('/home/isingh/code/variogram_data/V0/'+sim+'/G1/CSVs/publication_experimental_variogram_ensemble_*_randomly_distributed_sampling_20000_samples_binwidth_5km_estimator_'+order+'_order*_G1_environment_points_threshold_1e-07_'+var[0]+'_levtype_'+var[2]+'_lev_'+str(var[1])+'_*.csv'))\n",
    "            print(vario_files)\n",
    "            for csv_file in vario_files:\n",
    "                df = pd.read_csv(csv_file)\n",
    "\n",
    "            # Define a linear model for curve fitting\n",
    "            def linear_model(x, a, b):\n",
    "                return a * x + b\n",
    "            \n",
    "            df_filtered = df[(df['bins'] > 9) & (df['bins'] < 101)]\n",
    "            # Use log10 of bins and exp_variogram for curve fitting\n",
    "            log_bins = np.log10(df_filtered['bins'])\n",
    "            log_exp_variogram = np.log10(df_filtered['exp_variogram'])\n",
    "\n",
    "            # Fit the data\n",
    "            params, cov = curve_fit(linear_model, log_bins, log_exp_variogram)\n",
    "            slope, intercept = params\n",
    "            \n",
    "            slope_var = cov[0, 0]  # Variance of the slope\n",
    "            \n",
    "\n",
    "            # Calculate the fitted line\n",
    "            fitted_line = linear_model(log_bins, slope, intercept)\n",
    "          \n",
    "            # calculate R^2 \n",
    "            residuals = log_exp_variogram - linear_model(log_bins,  slope, intercept)\n",
    "            ss_res    = np.sum(residuals**2)\n",
    "            #You can get the total sum of squares (ss_tot) with\n",
    "            ss_tot    = np.sum((log_exp_variogram-np.mean(log_exp_variogram))**2)\n",
    "            #And finally, the r_squared-value with,\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            df_slope.loc[sim, order] = slope\n",
    "            df_slope.loc[sim, 'r_squared_'+order] = r_squared\n",
    "            df_error.loc[sim, order] = np.sqrt(slope_var)\n",
    "            \n",
    "    df_slope.to_csv('./structure_function_distance_log_slopes_'+var[0]+'_'+var[2]+'_level_'+str(var[1])+'.csv')  \n",
    "    print(df_slope)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
